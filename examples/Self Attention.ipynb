{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.27669192, -1.47350354, -3.19416925, -2.83136567],\n",
       "       [ 4.67557146,  1.42079285,  2.12530465, -1.643423  ],\n",
       "       [-3.63945806,  0.38888208,  2.12912139,  1.19110733],\n",
       "       [-1.41252549,  1.09485173, -0.14143964, -1.12710263]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np. matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9388843388110786, 0.6822663524883068, 7.112287132764719)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9388843388110786, 0.6822663524883068, 0.8890358915955898)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.21914571, -0.52096217, -1.12930937, -1.00103893],\n",
       "       [ 1.65306414,  0.50232613,  0.75140867, -0.58103777],\n",
       "       [-1.28674274,  0.13749058,  0.75275809,  0.42112003],\n",
       "       [-0.49940318,  0.38708854, -0.05000646, -0.39849096]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L)))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.21914571,        -inf,        -inf,        -inf],\n",
       "       [ 1.65306414,  0.50232613,        -inf,        -inf],\n",
       "       [-1.28674274,  0.13749058,  0.75275809,        -inf],\n",
       "       [-0.49940318,  0.38708854, -0.05000646, -0.39849096]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.75964569, 0.24035431, 0.        , 0.        ],\n",
       "       [0.07787287, 0.32353618, 0.59859094, 0.        ],\n",
       "       [0.16393047, 0.39779391, 0.25693909, 0.18133653]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = softmax(scaled + mask)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27921481, -1.61197661, -1.46371184, -0.4341913 ,  0.5109939 ,\n",
       "        -0.11487282, -0.09923813, -1.16228709],\n",
       "       [ 0.41773985, -1.18583877, -1.07289059, -0.03056215,  0.13426518,\n",
       "         0.00586366, -0.29655696, -1.41607961],\n",
       "       [-0.19557084,  0.42859128,  0.01657062, -0.04308915,  0.14843371,\n",
       "        -0.21634235,  0.79030764, -1.06602354],\n",
       "       [-0.04173758,  0.40657756, -0.45038202,  0.70766714, -0.11536355,\n",
       "         0.03321447,  0.0429623 , -1.06449782]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27921481, -1.61197661, -1.46371184, -0.4341913 ,  0.5109939 ,\n",
       "        -0.11487282, -0.09923813, -1.16228709],\n",
       "       [ 0.85555166,  0.16098034,  0.16230957,  1.24511768, -1.05639519,\n",
       "         0.38745427, -0.92018796, -2.2181971 ],\n",
       "       [-0.82546524,  0.83869889,  0.13037458, -0.68848027,  0.75247249,\n",
       "        -0.55589272,  1.8305484 , -0.43075473],\n",
       "       [-1.18976771,  2.15785595, -1.70125209,  2.53915519,  0.15306876,\n",
       "         0.22471616, -0.24850933,  0.65678704]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k ,v, mask=None):\n",
    "    d_k = q.shape[-1]\n",
    "    scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled = scaled + mask\n",
    "    attention = softmax(scaled)\n",
    "    out = np.matmul(attention, v)\n",
    "    return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.21827976  0.29169933  2.62722975  0.25567183 -1.62182615  0.40129385\n",
      "   1.7342214  -0.67822269]\n",
      " [ 1.18390483 -0.92181107  1.64459561  0.09108538 -0.91471029  1.17674544\n",
      "   2.00155926  0.75720602]\n",
      " [ 1.76490509 -0.51926953  0.03176173  0.01765212  1.5024297   0.12568892\n",
      "   0.18694038 -0.05733183]\n",
      " [-1.02020627 -0.59077518 -0.19402845  0.88391445  0.43880911  0.15582571\n",
      "  -0.52500026  0.12719653]]\n",
      "K\n",
      " [[-1.10833774  0.06313029  0.60030634 -1.06862347 -1.33234107  0.25729035\n",
      "   1.75435921  0.16254706]\n",
      " [-0.45045007 -0.43847875 -0.02290908  0.09556501  0.62228887  0.23556751\n",
      "   0.39095934  1.43731377]\n",
      " [ 0.73645148 -1.0672955  -0.89985083 -0.75474135  0.14289899  1.42211726\n",
      "  -0.16408379  0.79750106]\n",
      " [ 0.59247324 -0.42708696 -0.34280843 -0.88952517  0.1643907  -1.84336711\n",
      "  -0.14160905  0.67252263]]\n",
      "V\n",
      " [[ 0.27921481 -1.61197661 -1.46371184 -0.4341913   0.5109939  -0.11487282\n",
      "  -0.09923813 -1.16228709]\n",
      " [ 0.85555166  0.16098034  0.16230957  1.24511768 -1.05639519  0.38745427\n",
      "  -0.92018796 -2.2181971 ]\n",
      " [-0.82546524  0.83869889  0.13037458 -0.68848027  0.75247249 -0.55589272\n",
      "   1.8305484  -0.43075473]\n",
      " [-1.18976771  2.15785595 -1.70125209  2.53915519  0.15306876  0.22471616\n",
      "  -0.24850933  0.65678704]]\n",
      "New V\n",
      " [[ 0.27921481 -1.61197661 -1.46371184 -0.4341913   0.5109939  -0.11487282\n",
      "  -0.09923813 -1.16228709]\n",
      " [ 0.41773985 -1.18583877 -1.07289059 -0.03056215  0.13426518  0.00586366\n",
      "  -0.29655696 -1.41607961]\n",
      " [-0.19557084  0.42859128  0.01657062 -0.04308915  0.14843371 -0.21634235\n",
      "   0.79030764 -1.06602354]\n",
      " [-0.04173758  0.40657756 -0.45038202  0.70766714 -0.11536355  0.03321447\n",
      "   0.0429623  -1.06449782]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.75964569 0.24035431 0.         0.        ]\n",
      " [0.07787287 0.32353618 0.59859094 0.        ]\n",
      " [0.16393047 0.39779391 0.25693909 0.18133653]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "0.22239242133644774\n",
      "1.584962500721156\n",
      "-1.5849625007211563\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "def pointwise_mutual_information(x, y, pxy):\n",
    "    print(math.log( pxy / (x*y) , 2))\n",
    "\n",
    "pxy = [0.1, 0.7, 0.15, 0.05]\n",
    "x = [0.8, 0.8, 0.2, 0.2]\n",
    "y = [0.25, 0.75, 0.25, 0.75]\n",
    "\n",
    "for i in range(4):\n",
    "    pointwise_mutual_information(x[i], y[i], pxy[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMI: -1.0\n",
      "PMI: 0.22239242133644774\n",
      "PMI: 1.584962500721156\n",
      "PMI: -1.5849625007211563\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def pointwise_mutual_information(x, y, pxy):\n",
    "    p_x = x\n",
    "    p_y = y\n",
    "    pmi = math.log(pxy / (p_x * p_y), 2)\n",
    "    print(\"PMI:\", pmi)\n",
    "\n",
    "pxy = [0.1, 0.7, 0.15, 0.05]\n",
    "x = [0.8, 0.8, 0.2, 0.2]\n",
    "y = [0.25, 0.75, 0.25, 0.75]\n",
    "\n",
    "for i in range(4):\n",
    "    pointwise_mutual_information(x[i], y[i], pxy[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
